<!DOCTYPE html>
<html lang="en"><head>
<script src="04_largelanguagemodels_2023_files/libs/clipboard/clipboard.min.js"></script>
<script src="04_largelanguagemodels_2023_files/libs/quarto-html/tabby.min.js"></script>
<script src="04_largelanguagemodels_2023_files/libs/quarto-html/popper.min.js"></script>
<script src="04_largelanguagemodels_2023_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="04_largelanguagemodels_2023_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="04_largelanguagemodels_2023_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="04_largelanguagemodels_2023_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.1.251">

  <meta name="author" content="Dr.&nbsp;Philipp K. Masur">
  <title>Word Embeddings, Transformers, and Large Language Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="04_largelanguagemodels_2023_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="04_largelanguagemodels_2023_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="04_largelanguagemodels_2023_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="04_largelanguagemodels_2023_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="04_largelanguagemodels_2023_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="04_largelanguagemodels_2023_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="04_largelanguagemodels_2023_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="https://storage.googleapis.com/exenzo-jobboard/bb/public/thumb/logo-jpg-57.jpg" data-background-position="top right" data-background-size="auto" class="center">
  <h1 class="title">Word Embeddings, Transformers, and Large Language Models</h1>
  <p class="subtitle">Week 4: Bert, GPT, and Co</p>
  <p class="author">Dr.&nbsp;Philipp K. Masur</p>
</section>

<section id="section" class="slide level2" data-background="#43464B" data-background-video="video/imagination.mp4" data-background-video-loop="true" data-background-video-muted="true">
<h2></h2>
</section>
<section id="how-we-did-things-so-far" class="slide level2">
<h2>How we did things so far…</h2>
<ul>
<li><p>Remember the last practical session?</p></li>
<li><p>We dealt with the following data set of Dutch finance news headlines:</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Load data</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3"></a>url <span class="ot">&lt;-</span> <span class="st">"https://raw.githubusercontent.com/vanatteveldt/ecosent/master/data/intermediate/sentences_ml.csv"</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>d <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(url) <span class="sc">|&gt;</span> </span>
<span id="cb1-5"><a href="#cb1-5"></a>  <span class="fu">select</span>(id, <span class="at">text =</span> headline, lemmata, <span class="at">sentiment=</span>value) <span class="sc">|&gt;</span> </span>
<span id="cb1-6"><a href="#cb1-6"></a>  <span class="fu">mutate</span>(<span class="at">sentiment =</span> <span class="fu">factor</span>(sentiment, <span class="at">levels =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-7"><a href="#cb1-7"></a>                            <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"negative"</span>, <span class="st">"neutral"</span>, <span class="st">"positive"</span>)))</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="fu">head</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment">
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb2-1"><a href="#cb2-1"></a># A tibble: 6 × 4</span>
<span id="cb2-2"><a href="#cb2-2"></a>     id text                                                  lemmata  sentiment</span>
<span id="cb2-3"><a href="#cb2-3"></a>  &lt;dbl&gt; &lt;chr&gt;                                                 &lt;chr&gt;    &lt;fct&gt;    </span>
<span id="cb2-4"><a href="#cb2-4"></a>1 10007 Rabobank voorspelt flinke stijging hypotheekrente     Raboban… neutral  </span>
<span id="cb2-5"><a href="#cb2-5"></a>2 10027 D66 wil reserves provincies aanspreken voor groei     D66 wil… neutral  </span>
<span id="cb2-6"><a href="#cb2-6"></a>3 10037 UWV: dit jaar meer banen                              UWV dit… positive </span>
<span id="cb2-7"><a href="#cb2-7"></a>4 10059 Proosten op geslaagde beursgang Bols                  proost … positive </span>
<span id="cb2-8"><a href="#cb2-8"></a>5 10099 Helft werknemers gaat na 65ste met pensioen           helft w… neutral  </span>
<span id="cb2-9"><a href="#cb2-9"></a>6 10101 Europa groeit voorzichtig dankzij lage energieprijzen Europa … positive </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="the-classic-machine-learning-approach" class="slide level2">
<h2>The classic machine learning approach</h2>
<ul>
<li>A lot of different steps…</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Create test and train data sets</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(d, <span class="at">prop =</span> .<span class="dv">50</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co"># Feature engineering</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(sentiment <span class="sc">~</span> lemmata, <span class="at">data =</span> d) <span class="sc">|&gt;</span> </span>
<span id="cb3-6"><a href="#cb3-6"></a>  <span class="fu">step_tokenize</span>(lemmata) <span class="sc">|&gt;</span> </span>
<span id="cb3-7"><a href="#cb3-7"></a>  <span class="fu">step_tf</span>(<span class="fu">all_predictors</span>())  <span class="sc">|&gt;</span> </span>
<span id="cb3-8"><a href="#cb3-8"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb3-9"><a href="#cb3-9"></a></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co"># Setup algorithm/model</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>mlp_spec <span class="ot">&lt;-</span> <span class="fu">mlp</span>(<span class="at">epochs =</span> <span class="dv">600</span>, <span class="at">hidden_units =</span> <span class="fu">c</span>(<span class="dv">6</span>),  </span>
<span id="cb3-12"><a href="#cb3-12"></a>                <span class="at">penalty =</span> <span class="fl">0.01</span>, <span class="at">learn_rate =</span> <span class="fl">0.2</span>) <span class="sc">|&gt;</span>   </span>
<span id="cb3-13"><a href="#cb3-13"></a>  <span class="fu">set_engine</span>(<span class="st">"brulee"</span>) <span class="sc">|&gt;</span>    </span>
<span id="cb3-14"><a href="#cb3-14"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb3-15"><a href="#cb3-15"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co"># Create workflow</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>mlp_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> </span>
<span id="cb3-18"><a href="#cb3-18"></a>  <span class="fu">add_recipe</span>(rec) <span class="sc">|&gt;</span> </span>
<span id="cb3-19"><a href="#cb3-19"></a>  <span class="fu">add_model</span>(mlp_spec)</span>
<span id="cb3-20"><a href="#cb3-20"></a></span>
<span id="cb3-21"><a href="#cb3-21"></a><span class="co"># Fit model</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>m_mlp <span class="ot">&lt;-</span> <span class="fu">fit</span>(mlp_workflow, <span class="at">data =</span> <span class="fu">training</span>(split))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="what-if-things-were-easier" class="slide level2">
<h2>What if things were easier?</h2>
<ul>
<li>Wouldn’t it be great if we would not have to wrangle with the data, not engage in text preprocessing, and simply let the “computer” figure this out?</li>
</ul>
<div class="cell">

</div>
<div class="cell" data-r.options="{&quot;width&quot;:120}">
<div class="sourceCode cell-code" id="cb4" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="fu">gpt_zeroshot</span>(<span class="at">txt =</span> d[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,]<span class="sc">$</span>text,</span>
<span id="cb4-2"><a href="#cb4-2"></a>             <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"negative"</span>, <span class="st">"neutral"</span>, <span class="st">"positive"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-r.options="{&quot;width&quot;:160}">
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb5-1"><a href="#cb5-1"></a># A tibble: 3 × 1</span>
<span id="cb5-2"><a href="#cb5-2"></a>  labels  </span>
<span id="cb5-3"><a href="#cb5-3"></a>  &lt;chr&gt;   </span>
<span id="cb5-4"><a href="#cb5-4"></a>1 negative</span>
<span id="cb5-5"><a href="#cb5-5"></a>2 positive</span>
<span id="cb5-6"><a href="#cb5-6"></a>3 neutral </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="fragment">
<div class="cell">
<div class="sourceCode cell-code" id="cb6" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>d[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,]<span class="sc">|&gt;</span> </span>
<span id="cb6-2"><a href="#cb6-2"></a>  <span class="fu">bind_cols</span>(results) <span class="sc">|&gt;</span> </span>
<span id="cb6-3"><a href="#cb6-3"></a>  <span class="fu">select</span>(id, text, <span class="at">truth=</span>sentiment, <span class="at">predicted=</span>labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb7-1"><a href="#cb7-1"></a># A tibble: 3 × 4</span>
<span id="cb7-2"><a href="#cb7-2"></a>     id text                                              truth    predicted</span>
<span id="cb7-3"><a href="#cb7-3"></a>  &lt;dbl&gt; &lt;chr&gt;                                             &lt;fct&gt;    &lt;chr&gt;    </span>
<span id="cb7-4"><a href="#cb7-4"></a>1 10007 Rabobank voorspelt flinke stijging hypotheekrente neutral  negative </span>
<span id="cb7-5"><a href="#cb7-5"></a>2 10027 D66 wil reserves provincies aanspreken voor groei neutral  positive </span>
<span id="cb7-6"><a href="#cb7-6"></a>3 10037 UWV: dit jaar meer banen                          positive neutral  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="section-1" class="slide level2" data-background-image="https://ychef.files.bbci.co.uk/976x549/p01pqw85.jpg">
<h2></h2>
</section>
<section id="content-of-this-lecture" class="slide level2 smaller">
<h2>Content of this Lecture</h2>
<div class="columns">
<div class="column" style="width:45%;">
<ol type="1">
<li><p>Machine Learning vs.&nbsp;Deep Learning</p>
<p>1.1. Reminder: Machine Learning Text classification Pipeline</p>
<p>1.2. How did the field move on?</p></li>
<li><p>From Term Frequencies to Word-Embeddings</p>
<p>2.1. Basic principles</p>
<p>2.2. Similarity of words and texts</p>
<p>2.3. Pre-trained Word-Embeddings</p>
<p>2.4. Text Classification Pipeline with Word-Embeddings</p>
<p>2.5. Examples in the literature</p></li>
<li><p>The Rise of Transformers and Transfer Learning</p>
<p>3.1. Overview and Principles</p>
<p>3.2. Architecture of the Transformer Model</p>
<p>3.3. The Transformer/LLM Text Classification Pipeline</p>
<p>3.4. The Concept of Fine-Tuning</p></li>
</ol>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:45%;">
<ol start="4" type="1">
<li><p>Large Language Models: BERT, GPT and the “AI Revolution”?</p>
<p>4.1. What are Large Language Models and Generative AI?</p>
<p>4.2. A Peek into the Architecture of Famous LLMs</p>
<p>4.3. Zero-Shot Text Classification Using BERT and GPT</p>
<p>4.4. Validation, validation, validation!</p>
<p>4.5. Examples in the Literature</p></li>
<li><p>Summary and conclusion</p>
<p>5.1. A Look Back at the Chronology of NLP</p>
<p>5.2. State-of-the-Art in Classification</p>
<p>5.3. Ethical considerations</p>
<p>5.4. Conclusion</p></li>
</ol>
</div>
</div>
</section>
<section>
<section id="machine-learning-vs.-deep-learning" class="title-slide slide level1 center" data-background-color="steelblue">
<h1>Machine Learning vs.&nbsp;Deep Learning</h1>

</section>
<section id="text-classification-pipeline" class="slide level2">
<h2>Text Classification Pipeline</h2>

<img data-src="img/text_analysis_fundamentals/Slide01.png" class="r-stretch"></section>
<section id="machine-learning-1990-2010" class="slide level2">
<h2>Machine Learning (1990-2010)</h2>

<img data-src="img/text_analysis_fundamentals/Slide03.png" class="r-stretch"></section>
<section id="and-now" class="slide level2">
<h2>And now?</h2>

<img data-src="img/timeline/Slide3.png" class="r-stretch"></section>
<section id="massive-advancements-in-recent-years" class="slide level2">
<h2>Massive advancements in recent years</h2>
<ol type="1">
<li><p>Massive advancement in how text can be represented at numbers</p>
<ul>
<li>From simple word counts to word embeddings</li>
<li>Static vs.&nbsp;contextual word embeddings</li>
</ul></li>
<li><p>Pretraining and transfer learning</p>
<ul>
<li>Word embeddings can be trained on large scale corpus</li>
<li>Pretrained word embeddings can fine-tuned (less training data) and then used for downstream tasks</li>
</ul></li>
<li><p>Transformers and Generative AI</p>
<ul>
<li>Larger and larger “language models”</li>
<li>Ever more powerful in solving rather complex tasks</li>
<li>Conversational frameworks (e.g., GPT)</li>
</ul></li>
</ol>
</section></section>
<section>
<section id="from-term-frequencies-to-word-embeddings" class="title-slide slide level1 center" data-background-color="steelblue">
<h1>From Term Frequencies to Word-Embeddings</h1>
<p>More powerful and informative ways to represent text as numbers.</p>
</section>
<section id="rember-the-initial-problem-of-text-analysis" class="slide level2">
<h2>Rember: The initial problem of text analysis</h2>
<ul>
<li><p>Computers don’t read text, they only can deal with numbers</p></li>
<li><p>For this reason, so far, we tokenized our texts (e.g., in words) and summarized their frequency across texts to create a document-feature matrix within the bag-of-words model</p></li>
</ul>

<img data-src="img/simple_dfm.png" class="r-stretch"><ul>
<li><p>Such a text representation has some issues:</p>
<ul>
<li>Treats words as equally important (→ requires removal of noise, stopwords…)</li>
<li>Ignores word order and context</li>
<li>Results in a sparse matrix (→ computationally expensive)</li>
</ul></li>
</ul>
</section>
<section id="alternative-map-words-into-a-vector-space" class="slide level2">
<h2>Alternative: Map words into a vector space</h2>

<img data-src="img/word_embeddings1.png" class="r-stretch"></section>
<section id="static-word-embeddings" class="slide level2">
<h2>(Static) Word embeddings</h2>
<ul>
<li><p>Word embeddings are a “learned” type of <strong>word representation</strong> that allows words with similar meaning to have a similar representation via a <em>k</em>-dimensional vector space</p></li>
<li><p>The first core idea behind word embeddings is that the meaning of a word can be expressed using a relatively small embedding vector, generally consisting of around 300 numbers which can be interpreted as dimensions of meaning.</p></li>
<li><p>The second core idea is that these embedding vectors can be derived by scanning the context of each word in millions and millions of documents.</p></li>
<li><p>This means that words that are used in similar ways in the training data result in similar representations, thereby capturing their similar meaning.</p></li>
<li><p>This can be contrasted with the crisp but rather limited representation of words in a bag of words model where different words have different representations, regardless of how they are used.</p></li>
</ul>
</section>
<section id="how-do-we-get-these-values-for-each-word" class="slide level2">
<h2>How do we get these “values” for each word?</h2>
<ul>
<li><p>All word embedding methods learn a real-valued vector representation for a predefined fixed sized vocabulary from a corpus of text.</p></li>
<li><p>There are many different ways to “learn” or use word embeddings:</p></li>
</ul>
<p><br></p>
<ol type="1">
<li><p>Via an embedding layer in a neural network designed for a particular downstream task</p></li>
<li><p>Learning word embeddings using a shallow neural network and context windows (e.g., <strong>word2vec</strong>)</p></li>
<li><p>Leatning word embeddings by aggregating global word-word co-occurrence matrix (e.g., GloVe)</p></li>
</ol>
</section>
<section id="word2vec-continuous-bag-of-words-cbow" class="slide level2">
<h2>Word2Vec: Continuous Bag-of-words (CBOW)</h2>

<img data-src="img/cbow/Slide1.png" class="r-stretch"></section>
<section id="word2vec-continuous-bag-of-words-cbow-1" class="slide level2">
<h2>Word2Vec: Continuous Bag-of-words (CBOW)</h2>

<img data-src="img/cbow/Slide2.png" class="r-stretch"></section>
<section id="word2vec-continuous-bag-of-words-cbow-2" class="slide level2">
<h2>Word2Vec: Continuous Bag-of-words (CBOW)</h2>

<img data-src="img/cbow/Slide3.png" class="r-stretch"></section>
<section id="word2vec-continuous-bag-of-words-cbow-3" class="slide level2">
<h2>Word2Vec: Continuous Bag-of-words (CBOW)</h2>

<img data-src="img/cbow/Slide4.png" class="r-stretch"></section>
<section id="word2vec-continuous-bag-of-words-cbow-4" class="slide level2">
<h2>Word2Vec: Continuous Bag-of-words (CBOW)</h2>

<img data-src="img/cbow/Slide5.png" class="r-stretch"></section>
<section id="word2vec-continuous-bag-of-words-cbow-5" class="slide level2">
<h2>Word2Vec: Continuous Bag-of-words (CBOW)</h2>

<img data-src="img/cbow/Slide6.png" class="r-stretch"></section>
<section id="pre-trained-word-embeddings-glove" class="slide level2">
<h2>Pre-trained Word embeddings: GloVe</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>glove_fn <span class="ot">=</span> <span class="st">"glove.6B.50d.10k.w2v.txt"</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>url <span class="ot">=</span> glue<span class="sc">::</span><span class="fu">glue</span>(<span class="st">"https://cssbook.net/d/{glove_fn}"</span>)</span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">file.exists</span>(glove_fn)) </span>
<span id="cb8-4"><a href="#cb8-4"></a>    <span class="fu">download.file</span>(url, glove_fn)</span>
<span id="cb8-5"><a href="#cb8-5"></a></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="co"># Data wrangling</span></span>
<span id="cb8-7"><a href="#cb8-7"></a>wv_tibble <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(glove_fn, <span class="at">skip=</span><span class="dv">1</span>, <span class="at">delim=</span><span class="st">" "</span>, <span class="at">quote=</span><span class="st">""</span>, </span>
<span id="cb8-8"><a href="#cb8-8"></a>    <span class="at">col_names =</span> <span class="fu">c</span>(<span class="st">"word"</span>, <span class="fu">paste0</span>(<span class="st">"d"</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>)))</span>
<span id="cb8-9"><a href="#cb8-9"></a></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="co"># 10 highest scoring words on dimension 1</span></span>
<span id="cb8-11"><a href="#cb8-11"></a>wv_tibble <span class="sc">|&gt;</span> </span>
<span id="cb8-12"><a href="#cb8-12"></a>  <span class="fu">arrange</span>(<span class="sc">-</span>d1) <span class="sc">|&gt;</span> </span>
<span id="cb8-13"><a href="#cb8-13"></a>  <span class="fu">select</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb9-1"><a href="#cb9-1"></a># A tibble: 10,000 × 10</span>
<span id="cb9-2"><a href="#cb9-2"></a>   word          d1     d2      d3      d4      d5     d6      d7      d8     d9</span>
<span id="cb9-3"><a href="#cb9-3"></a>   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;</span>
<span id="cb9-4"><a href="#cb9-4"></a> 1 airbus      2.60 -0.536  0.414   0.339  -0.0510  0.848 -0.722  -0.361   0.869</span>
<span id="cb9-5"><a href="#cb9-5"></a> 2 spacecraft  2.52  0.744  1.66    0.0591 -0.252  -0.243 -0.594  -0.417   0.460</span>
<span id="cb9-6"><a href="#cb9-6"></a> 3 fiat        2.29 -1.15   0.488   0.518   0.312  -0.132  0.0520 -0.661  -0.859</span>
<span id="cb9-7"><a href="#cb9-7"></a> 4 naples      2.27 -0.106 -1.27   -0.0932 -0.437  -1.18  -0.0858  0.469  -1.08 </span>
<span id="cb9-8"><a href="#cb9-8"></a> 5 di          2.24 -0.603 -1.47    0.354   0.244  -1.09   0.357  -0.331  -0.564</span>
<span id="cb9-9"><a href="#cb9-9"></a> 6 planes      2.20 -0.831  1.34   -0.348  -0.209  -0.282 -0.824  -0.481   0.211</span>
<span id="cb9-10"><a href="#cb9-10"></a> 7 bombings    2.16 -0.222  0.383   0.0723 -0.305   0.632  0.125  -0.123  -0.171</span>
<span id="cb9-11"><a href="#cb9-11"></a> 8 flights     2.15  0.350 -0.0175 -0.0238 -1.39   -0.812 -0.742   0.204   1.23 </span>
<span id="cb9-12"><a href="#cb9-12"></a> 9 orbit       2.14  1.08   1.66   -0.180   0.323  -0.394  0.0476 -0.0108  0.403</span>
<span id="cb9-13"><a href="#cb9-13"></a>10 plane       2.11 -0.107  0.972   0.122   0.571  -0.136 -0.676   0.117   0.472</span>
<span id="cb9-14"><a href="#cb9-14"></a># ℹ 9,990 more rows</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="similarities-between-words" class="slide level2">
<h2>Similarities between words</h2>
<p>As mentioned before, we can compute similarity scores for word pairs:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>wv <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(wv_tibble[<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="fu">rownames</span>(wv) <span class="ot">&lt;-</span> wv_tibble<span class="sc">$</span>word</span>
<span id="cb10-3"><a href="#cb10-3"></a>wv <span class="ot">&lt;-</span> wv <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">rowSums</span>(wv<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb10-4"><a href="#cb10-4"></a>wvector <span class="ot">&lt;-</span> <span class="cf">function</span>(wv, word) wv[word,,drop<span class="ot">=</span>F]</span>
<span id="cb10-5"><a href="#cb10-5"></a>wv_similar <span class="ot">&lt;-</span> <span class="cf">function</span>(wv, target, <span class="at">n=</span><span class="dv">5</span>) {</span>
<span id="cb10-6"><a href="#cb10-6"></a>  similarities <span class="ot">=</span> wv <span class="sc">%*%</span> <span class="fu">t</span>(target)</span>
<span id="cb10-7"><a href="#cb10-7"></a>  similarities <span class="sc">|&gt;</span>  </span>
<span id="cb10-8"><a href="#cb10-8"></a>    <span class="fu">as_tibble</span>(<span class="at">rownames =</span> <span class="st">"word"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb10-9"><a href="#cb10-9"></a>    <span class="fu">rename</span>(<span class="at">similarity=</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb10-10"><a href="#cb10-10"></a>    <span class="fu">arrange</span>(<span class="sc">-</span>similarity) <span class="sc">|&gt;</span>  </span>
<span id="cb10-11"><a href="#cb10-11"></a>    <span class="fu">head</span>(<span class="at">n=</span>n)  </span>
<span id="cb10-12"><a href="#cb10-12"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell" data-output-location="fragment">
<div class="sourceCode cell-code" id="cb11" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">wv_similar</span>(wv, <span class="fu">wvector</span>(wv, <span class="st">"basketball"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb12-1"><a href="#cb12-1"></a># A tibble: 5 × 2</span>
<span id="cb12-2"><a href="#cb12-2"></a>  word       similarity</span>
<span id="cb12-3"><a href="#cb12-3"></a>  &lt;chr&gt;           &lt;dbl&gt;</span>
<span id="cb12-4"><a href="#cb12-4"></a>1 basketball      1    </span>
<span id="cb12-5"><a href="#cb12-5"></a>2 football        0.879</span>
<span id="cb12-6"><a href="#cb12-6"></a>3 hockey          0.862</span>
<span id="cb12-7"><a href="#cb12-7"></a>4 baseball        0.861</span>
<span id="cb12-8"><a href="#cb12-8"></a>5 nba             0.838</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell" data-output-location="fragment">
<div class="sourceCode cell-code" id="cb13" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="fu">wv_similar</span>(wv, <span class="fu">wvector</span>(wv, <span class="st">"netherlands"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb14-1"><a href="#cb14-1"></a># A tibble: 5 × 2</span>
<span id="cb14-2"><a href="#cb14-2"></a>  word        similarity</span>
<span id="cb14-3"><a href="#cb14-3"></a>  &lt;chr&gt;            &lt;dbl&gt;</span>
<span id="cb14-4"><a href="#cb14-4"></a>1 netherlands      1    </span>
<span id="cb14-5"><a href="#cb14-5"></a>2 belgium          0.893</span>
<span id="cb14-6"><a href="#cb14-6"></a>3 switzerland      0.821</span>
<span id="cb14-7"><a href="#cb14-7"></a>4 denmark          0.809</span>
<span id="cb14-8"><a href="#cb14-8"></a>5 france           0.789</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="similarity-of-entire-sentences-or-texts" class="slide level2">
<h2>Similarity of entire sentences or texts</h2>
<p>But we can also generalize word embeddings to entire sentences (or even texts):</p>
<div class="cell" data-r.options="{&quot;width&quot;:120}">
<div class="sourceCode cell-code" id="cb15" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="fu">library</span>(ccsamsterdamR)</span>
<span id="cb15-2"><a href="#cb15-2"></a></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="co"># Example sentences</span></span>
<span id="cb15-4"><a href="#cb15-4"></a>movies <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sentences =</span> <span class="fu">c</span>(<span class="st">"This movie is great, I loved it."</span>, </span>
<span id="cb15-5"><a href="#cb15-5"></a>                               <span class="st">"The film was fantastic, a real treat!"</span>,</span>
<span id="cb15-6"><a href="#cb15-6"></a>                               <span class="st">"I did not like this movie, it was not great."</span>,</span>
<span id="cb15-7"><a href="#cb15-7"></a>                               <span class="st">"Today, I went to the cinema and watched a movie"</span>,</span>
<span id="cb15-8"><a href="#cb15-8"></a>                               <span class="st">"I had pizza for lunch."</span>))</span>
<span id="cb15-9"><a href="#cb15-9"></a>                     </span>
<span id="cb15-10"><a href="#cb15-10"></a><span class="co"># Get embeddings from a sentence transformer</span></span>
<span id="cb15-11"><a href="#cb15-11"></a>movie_embeddings <span class="ot">&lt;-</span> <span class="fu">hf_embeddings</span>(<span class="at">txt =</span> movies<span class="sc">$</span>sentences)</span>
<span id="cb15-12"><a href="#cb15-12"></a></span>
<span id="cb15-13"><a href="#cb15-13"></a><span class="co"># Each text has now 384 values</span></span>
<span id="cb15-14"><a href="#cb15-14"></a>movie_embeddings </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb16-1"><a href="#cb16-1"></a># A tibble: 5 × 384</span>
<span id="cb16-2"><a href="#cb16-2"></a>       V1       V2      V3       V4      V5       V6       V7      V8      V9      V10     V11      V12      V13     V14</span>
<span id="cb16-3"><a href="#cb16-3"></a>    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;</span>
<span id="cb16-4"><a href="#cb16-4"></a>1 -0.0875 -0.0156  -0.0380 -0.0586  -0.0842  0.0164  -0.0222   0.0451  0.0449 -0.00546 -0.0115 -0.00166  0.00575  0.0362</span>
<span id="cb16-5"><a href="#cb16-5"></a>2 -0.0544  0.0381  -0.0443 -0.0111  -0.0464 -0.00760 -0.0523   0.0173 -0.0725 -0.0432   0.0206  0.00903  0.0223   0.0208</span>
<span id="cb16-6"><a href="#cb16-6"></a>3 -0.0838  0.0135  -0.0938 -0.0351  -0.0848 -0.0424  -0.00107  0.0537  0.0559 -0.0729   0.0153  0.0359   0.0396   0.0387</span>
<span id="cb16-7"><a href="#cb16-7"></a>4 -0.0442  0.00655  0.0754 -0.0341   0.0637  0.00674  0.0993  -0.0369  0.0752 -0.0405   0.0222  0.0284  -0.0243   0.0916</span>
<span id="cb16-8"><a href="#cb16-8"></a>5 -0.0257  0.0440   0.0407  0.00391 -0.0818 -0.0621   0.0836  -0.0138 -0.101  -0.0757   0.0882 -0.0530   0.0351  -0.0716</span>
<span id="cb16-9"><a href="#cb16-9"></a># ℹ 370 more variables: V15 &lt;dbl&gt;, V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;, V22 &lt;dbl&gt;,</span>
<span id="cb16-10"><a href="#cb16-10"></a>#   V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;, V31 &lt;dbl&gt;, V32 &lt;dbl&gt;,</span>
<span id="cb16-11"><a href="#cb16-11"></a>#   V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;, V36 &lt;dbl&gt;, V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;, V42 &lt;dbl&gt;,</span>
<span id="cb16-12"><a href="#cb16-12"></a>#   V43 &lt;dbl&gt;, V44 &lt;dbl&gt;, V45 &lt;dbl&gt;, V46 &lt;dbl&gt;, V47 &lt;dbl&gt;, V48 &lt;dbl&gt;, V49 &lt;dbl&gt;, V50 &lt;dbl&gt;, V51 &lt;dbl&gt;, V52 &lt;dbl&gt;,</span>
<span id="cb16-13"><a href="#cb16-13"></a>#   V53 &lt;dbl&gt;, V54 &lt;dbl&gt;, V55 &lt;dbl&gt;, V56 &lt;dbl&gt;, V57 &lt;dbl&gt;, V58 &lt;dbl&gt;, V59 &lt;dbl&gt;, V60 &lt;dbl&gt;, V61 &lt;dbl&gt;, V62 &lt;dbl&gt;,</span>
<span id="cb16-14"><a href="#cb16-14"></a>#   V63 &lt;dbl&gt;, V64 &lt;dbl&gt;, V65 &lt;dbl&gt;, V66 &lt;dbl&gt;, V67 &lt;dbl&gt;, V68 &lt;dbl&gt;, V69 &lt;dbl&gt;, V70 &lt;dbl&gt;, V71 &lt;dbl&gt;, V72 &lt;dbl&gt;,</span>
<span id="cb16-15"><a href="#cb16-15"></a>#   V73 &lt;dbl&gt;, V74 &lt;dbl&gt;, V75 &lt;dbl&gt;, V76 &lt;dbl&gt;, V77 &lt;dbl&gt;, V78 &lt;dbl&gt;, V79 &lt;dbl&gt;, V80 &lt;dbl&gt;, V81 &lt;dbl&gt;, V82 &lt;dbl&gt;, …</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="the-subtle-similarity-of-some-texts-in-the-example" class="slide level2">
<h2>The subtle similarity of some texts in the example</h2>
<ul>
<li><p>We can see that text 2 is most similar to text 1: Both express a very similar sentiment, just with different words (“great” ≈ “fantastic”; “I loved it” ≈ “A real treat”)</p></li>
<li><p>Text 2 is still similar to text 3 (after all it is about movies), but less so compared to text 1 (“fantastic” is the opposite of “not great”)</p></li>
<li><p>Text 4 still shares similarities (the context is the cinema/watching movies), but text 5 is very different as it doesn’t contain similar words and is not about similar things (except “I”).</p></li>
</ul>
<div class="cell" data-r.options="{&quot;width&quot;:120}">
<div class="sourceCode cell-code" id="cb17" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># Similarity between 2nd and the other sentences</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>movies <span class="sc">|&gt;</span> </span>
<span id="cb17-3"><a href="#cb17-3"></a>  <span class="fu">mutate</span>(<span class="at">similarity =</span> <span class="fu">as.matrix</span>(movie_embeddings) <span class="sc">%*%</span> <span class="fu">t</span>(<span class="fu">as.matrix</span>(movie_embeddings)[<span class="dv">2</span>,, <span class="at">drop =</span> F]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb18-1"><a href="#cb18-1"></a># A tibble: 5 × 2</span>
<span id="cb18-2"><a href="#cb18-2"></a>  sentences                                       similarity[,1]</span>
<span id="cb18-3"><a href="#cb18-3"></a>  &lt;chr&gt;                                                    &lt;dbl&gt;</span>
<span id="cb18-4"><a href="#cb18-4"></a>1 This movie is great, I loved it.                         0.646</span>
<span id="cb18-5"><a href="#cb18-5"></a>2 The film was fantastic, a real treat!                    1.00 </span>
<span id="cb18-6"><a href="#cb18-6"></a>3 I did not like this movie, it was not great.             0.513</span>
<span id="cb18-7"><a href="#cb18-7"></a>4 Today, I went to the cinema and watched a movie          0.372</span>
<span id="cb18-8"><a href="#cb18-8"></a>5 I had pizza for lunch.                                   0.132</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="word-embeddings-as-input" class="slide level2">
<h2>Word Embeddings as Input</h2>
<ul>
<li><p>Word, sentence, or text embedding vectors can then be used as features in further text analysis tasks</p></li>
<li><p>Think about the example we just investigated: The sentence embeddings did capturesome difference between:</p>
<ul>
<li>“The film was fantastic, a real treat!” (<em>positive</em>)</li>
<li>“I did not like this moive, it was not great.” (<em>negative</em>)</li>
</ul></li>
<li><p>Approaches from the last lecture (classic machine learning) would have a hard time to detect the negation “not great”.</p></li>
<li><p>Yet, bear in mind: We do not actually know what the 100+ (often &gt;300) dimensions actually mean (→ we cannot look under the hood later!)</p></li>
</ul>
</section>
<section id="from-sparse-to-dense-matrix-representation" class="slide level2">
<h2>From Sparse to Dense Matrix Representation</h2>
<ul>
<li><p>Using embedding vectors instead of word frequencies further has the advantages of strongly reducing the dimensionality of the DTM: instead of (tens of) thousands of columns for each unique word we only need hundreds of columns for the embedding vectors (→ dense instead of sparse)</p></li>
<li><p>This means that further processing can be more efficient as fewer parameters need to be fit, or conversely that more complicated models can be used without blowing up the parameter space.</p></li>
</ul>
</section>
<section id="text-classification-with-word-embeddings" class="slide level2">
<h2>Text classification with Word-Embeddings</h2>

<img data-src="img/text_analysis_fundamentals/Slide04.png" class="r-stretch"></section>
<section id="doing-analysis-with-word-embedding-themselves" class="slide level2">
<h2>Doing analysis with word-embedding themselves</h2>
<ul>
<li><p>Based on vector-based computations, we can also analyse semantic relationships</p></li>
<li><p>This is a quite common approach by now in research on gender and other types of stereotypes</p></li>
</ul>

<img data-src="https://miro.medium.com/v2/resize:fit:2000/1*SYiW1MUZul1NvL1kc1RxwQ.png" class="r-stretch quarto-figure-center"><p class="caption">Source: https://developers.google.com</p></section>
<section id="example-from-the-literature-gender-stereotypes" class="slide level2">
<h2>Example from the literature: Gender-Stereotypes</h2>
<ul>
<li><p><img data-src="img/andrich_example.png" style="float: right; padding-left: 40px;" width="400">Andrich et al.&nbsp;(2023) examine stereotypical traits in portrayals of 1,095 U.S. politicians.</p></li>
<li><p>Analyzed 5 million U.S. news stories published from 2010 to 2020 to study gender-linked (feminine, masculine) and political (leadership, competence, integrity, empathy) traits</p></li>
<li><p>Methodologically, they estimated word embeddings using the Continuous Bag of Words (CBOW) model, meaning that a target word (e.g., honest) is predicted from its context (e.g., Who thinks President Trump is [target word]?)</p></li>
<li><p>Bias can thus be identified if e.g., gender-neutral words (e.g., competent) are closer to words that represent one gender (e.g., donald_trump) than to words that represent the opposite gender (e.g., hillary_clinton).</p></li>
</ul>
</section>
<section id="results" class="slide level2">
<h2>Results</h2>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 49.0%;justify-content: center;">
<p><img data-src="img/andrich_fig2.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 51.0%;justify-content: center;">
<p><img data-src="img/andrich_fig1.jpeg"></p>
</div>
</div>
</div>
<ul>
<li><p>All three masculine traits were more strongly associated with male politicians.</p></li>
<li><p>In contrast, only the feminine physical traits were more strongly associated with female politicians.</p></li>
<li><p>Differences remained stable across time.</p></li>
</ul>
</section></section>
<section>
<section id="the-rise-of-transformers-and-transfer-learning" class="title-slide slide level1 centered center" data-background-color="steelblue">
<h1>The Rise of Transformers and Transfer Learning</h1>
<center>
<img data-src="https://pyxis.nymag.com/v1/imgs/7e2/b83/01a7d3094f5856a53f409a59b9d16e392e-22-transformers-fighting.2x.rhorizontal.w710.jpg" style="width:65.0%">
</center>
</section>
<section id="origin-of-transformer-models" class="slide level2">
<h2>Origin of Transformer Models</h2>
<ul>
<li><p>Until 2017, the state-of-the-art for natural language processing was using a deep neural network (e.g., recurrent neural networks, long short-term memory and gated recurrent neural networks)</p></li>
<li><p>In a preprint called “Attention is all you need”, published in 2017 and cited more than 95,000 times, the team of Google Brain introduced the so-called <strong>Transformer</strong>, a a neural network-type architecture that learns context and thus meaning by tracking relationships in sequential data like the words in this sentence.</p></li>
<li><p>Transformer models apply an evolving set of mathematical techniques, called <strong>attention</strong> or <strong>self-attention</strong>, to detect subtle ways even distant data elements in a series influence and depend on each other.</p></li>
<li><p>The proposed network structure had notable characteristics:</p>
<ul>
<li>No need for recurrent or convolutional network structures</li>
<li>Based solely on attention mechanism (stacked on top of one another)</li>
<li>Requires less training time (can be parallelized)</li>
<li>Outperformed prior state-of-the-art models in a variety of tasks</li>
</ul></li>
</ul>
</section>
<section id="overview-of-the-architecture" class="slide level2">
<h2>OVerview of the architecture</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li><p>The figure on the right represent an abstract overview of a transformer’s architecture</p></li>
<li><p>It can be used for sequence-to-sequence predictions</p>
<ul>
<li>classic example is translation: e.g., english-to-dutch</li>
<li>but also: question-to-answer, text-to-summary, sentence-to-next-sentence…</li>
</ul></li>
<li><p>Although models can differ, they generally include:</p>
<ul>
<li>An encoder-decoder framework</li>
<li>Word embeddings + positional embedding</li>
<li>Attention and self-attention modules</li>
</ul></li>
<li><p>We won’t cover any of these in much detail and just aim for a high-level understanding</p></li>
</ul>
<p><span style="font-size:0.55em;">Vaswani et al.&nbsp;2017</span></p>
</div><div class="column" style="width:40%;">
<p><img data-src="img/transformer_architecture.png"></p>
</div>
</div>
</section>
<section id="basic-encoder-decoder-framework-for-translation" class="slide level2">
<h2>Basic Encoder-Decoder Framework (for Translation)</h2>

<img data-src="img/transformer/Slide01.png" class="r-stretch"></section>
<section id="stacked-encoders-and-decoders" class="slide level2">
<h2>Stacked Encoders and Decoders</h2>

<img data-src="img/transformer/Slide02.png" class="r-stretch"></section>
<section id="more-elaborate-encoding-of-words" class="slide level2">
<h2>More elaborate encoding of words</h2>

<img data-src="img/transformer/Slide03.png" class="r-stretch quarto-figure-center"><p class="caption">Source: Alammar, 2018</p></section>
<section id="inside-of-an-encoder-and-a-decoder" class="slide level2">
<h2>Inside of an encoder and a decoder</h2>
<ul>
<li><p>The word, position, and time signal embeddings are passed to the first encoder</p></li>
<li><p>Here, they flow through a self-attention layer, which further refines the encoding by “looking at other words” as it encodes a specific word</p></li>
<li><p>The outputs of the self-attention layer are fed to a feed-forward neural network.</p></li>
<li><p>The decoder likewise has both layers as well, but also an extra attention layer that helps to focus on different parts of the input (e.g., the encoders outputs)</p></li>
</ul>

<img data-src="img/transformer/encoder-decoder.png" class="r-stretch quarto-figure-center"><p class="caption">Source: Alammar, 2018</p></section>
<section id="encoding-pipeline" class="slide level2">
<h2>Encoding pipeline</h2>
<ul>
<li><p>The embedding only happens in the bottom-most encoder.</p></li>
<li><p>In other encoders, it would be the output of the encoder that’s directly below.</p></li>
</ul>

<img data-src="img/transformer/encoding-pipline.png" class="r-stretch quarto-figure-center"><p class="caption">Source: Alammar, 2018</p></section>
<section id="self-attention" class="slide level2">
<h2>Self-Attention</h2>
<ul>
<li><p>In general terms, self-attention works encodes how similar each word is to all the words in the sentence, including itself.</p></li>
<li><p>Once the similarities are calculated, they are used to determine how the transformers encodes each word.</p></li>
</ul>

<img data-src="img/transformer2/Slide1.png" class="r-stretch"></section>
<section id="self-attention-1" class="slide level2">
<h2>Self-Attention</h2>
<ul>
<li><p>In general terms, self-attention works encodes how similar each word is to all the words in the sentence, including itself.</p></li>
<li><p>Once the similarities are calculated, they are used to determine how the transformers encodes each word.</p></li>
</ul>

<img data-src="img/transformer2/Slide2.png" class="r-stretch"></section>
<section id="self-attention-2" class="slide level2">
<h2>Self-Attention</h2>
<ul>
<li><p>In general terms, self-attention works encodes how similar each word is to all the words in the sentence, including itself.</p></li>
<li><p>Once the similarities are calculated, they are used to determine how the transformers encodes each word.</p></li>
</ul>

<img data-src="img/transformer2/Slide3.png" class="r-stretch"></section>
<section id="self-attention-3" class="slide level2">
<h2>Self-Attention</h2>
<ul>
<li><p>In general terms, self-attention works encodes how similar each word is to all the words in the sentence, including itself.</p></li>
<li><p>Once the similarities are calculated, they are used to determine how the transformers encodes each word.</p></li>
</ul>

<img data-src="img/transformer2/Slide5.png" class="r-stretch"></section>
<section id="self-attention-at-a-high-level" class="slide level2">
<h2>Self-Attention at a High Level</h2>
<ul>
<li><p>As the encoder processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.</p></li>
<li><p>On the decoder side, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to -inf) before the softmax step in the self-attention calculation.</p></li>
<li><p>The actual architecture of this step is incredibly complex, so we keep it at that for now.</p></li>
</ul>
</section>
<section id="putting-it-all-together" class="slide level2">
<h2>Putting it all together</h2>

<img data-src="img/transformer/Slide10.png" class="r-stretch quarto-figure-center"><p class="caption">Source: Alammar, 2018</p></section>
<section id="high-level-process" class="slide level2">
<h2>High-level process</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ol type="1">
<li><p>The transformers starts by creating word embeddings (combinations of similarity, position, time signal)</p></li>
<li><p>The encoder start by processing the input sequence (embeddings).</p></li>
<li><p>The output of the top encoder is then transformed into a set of attention vectors which are used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence</p></li>
<li><p>The decoder spits out a first output (e.g., the word “I”), which then becomes the input for the decoder in follow-up steps</p></li>
<li><p>The decoder repeats these steps until a special symbol (e.g., <eos> = “end of sentence”) is reached.</eos></p></li>
</ol>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img/transformer_architecture.png"></p>
<p></p><figcaption>Source: Vaswani et al., 2017</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="text-classification-pipeline-using-transformers" class="slide level2">
<h2>Text Classification Pipeline Using Transformers</h2>

<img data-src="img/text_analysis_fundamentals/Slide05.png" class="r-stretch"></section>
<section id="pre-training-and-transfer-learning" class="slide level2">
<h2>Pre-training and transfer learning</h2>
<ul>
<li><p>Generally, transformer models are pre-trained using specific natural language processing tasks</p></li>
<li><p>It has been shown that these (often self- or unsupervised) trainings are often sufficient to let the model perform well on many down-stream tasks</p></li>
<li><p>However, the general idea would be to use a pre-trained model and then “fine-tune” it on the specific tasks it is supposed to perform (e.g., annotating text with topics or sentiment)</p></li>
<li><p>Although the transformer’s architecture has made training more efficient (due to the ability to parallelize), it nonetheless requires significant computing power to fine-tune a model</p></li>
<li><p>Luckily, transformers are the back-bone of today’s large language models, which - due to their immense training - are able to perform very well on most task without any specific fine-tuning (called: zero-shooting).</p></li>
<li><p>As pre-training often involves tasks that are different than what we want the model to do, this is often denoted as “transfer learning”, thus a type of learning that transfers to other task as well</p></li>
</ul>
</section></section>
<section>
<section id="large-language-models-bert-gpt-and-the-ai-revolution" class="title-slide slide level1 centered center" data-background-color="steelblue">
<h1>Large Language Models: BERT, GPT and the “AI Revolution”?</h1>
<center>
<p><img data-src="https://miro.medium.com/v2/resize:fit:1400/1*tjHTmF_1SUY6_pykU6_VpQ.gif" style="width:65.0%"></p>
<p><span style="font-size:55em;">Source: <a href="https://betterprogramming.pub/how-to-create-the-matrix-text-effect-with-javascript-325c6bb7d96e">Christian Behler on Medium</a></span></p>
</center>
</section>
<section id="what-are-large-language-models" class="slide level2">
<h2>What are large language models</h2>
<ul>
<li><p>A large language model (LLM) is a type of language model notable for its ability to achieve general-purpose language understanding and generation.</p></li>
<li><p>LLMs acquire these abilities by using massive amounts of data to learn billions of parameters during training and consuming large computational resources during their training and operation.</p></li>
<li><p>LLMs are still just a type of artificial neural networks (mainly transformers!) and are (pre-)trained using self-supervised learning and semi-supervised learning.</p></li>
<li><p>As so-called autoregressive language models, they take an <strong>input text</strong> and repeatedly <strong>predicting the next token</strong> or word.</p></li>
</ul>
</section>
<section id="fine-tuning-vs.-zero-shot-learning" class="slide level2">
<h2>Fine-tuning vs.&nbsp;zero-shot learning</h2>
<ul>
<li><p>Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks.</p></li>
<li><p>Larger sized models (since BERT and GPT-2 and 3), however, can be prompt-engineered to achieve similar results.</p></li>
<li><p>They are thought to acquire embodied knowledge about syntax, semantics and “ontology” inherent in human language corpora, but also inaccuracies and biases present in the corpora.</p></li>
<li><p>Notable examples include:</p>
<ul>
<li>OpenAI’s GPT models (e.g., GPT-3.5 and GPT-4, used in ChatGPT)</li>
<li>Google’s BERT and PaLM (used in Bard),</li>
<li>Meta’s LLaMa</li>
</ul></li>
</ul>
</section>
<section id="next-token-prediction-as-in-gpt-2" class="slide level2">
<h2>Next token prediction (as in GPT-2)</h2>

<img data-src="img/gpt2-1.png" class="r-stretch"></section>
<section id="next-token-prediction-as-in-gpt-2-1" class="slide level2">
<h2>Next token prediction (as in GPT-2)</h2>

<img data-src="img/gpt2-2.png" class="r-stretch"></section>
<section id="next-token-prediction" class="slide level2">
<h2>Next token prediction</h2>

<img data-src="img/gpt2-3.png" class="r-stretch"></section>
<section id="different-architectures" class="slide level2">
<h2>Different architectures</h2>
<ul>
<li><p>Encoder-Decoder Transformers:</p>
<ul>
<li>BART (Lewis et al., 2019): language generation, tanslation, comprehension,…</li>
</ul></li>
<li><p>Encoder-Only Transformer</p>
<ul>
<li>BERT (Devlin et al., 2019): Question answering, language inference,…</li>
</ul></li>
<li><p>Decoder-Only Transformer:</p>
<ul>
<li>GPT-series (OpenAI)</li>
</ul></li>
<li><p>In the following, we will focus on BERT and GPT</p></li>
</ul>
<p><br></p>
<p><strong>Note:</strong> Whereas many large language models are open source AND free to use (e.g., BERT), others are free to use only in limited capacity and essentially a black box when it comes to details about the architecture and training form and training data (e.g., GPT-3 or GPT-4).</p>
</section>
<section id="bert" class="slide level2">
<h2>Bert</h2>
<div class="columns">
<div class="column" style="width:85%;">
<ul>
<li><p>Bidirectional Encoder Representations from Transformers (BERT) is a family of language models introduced in October 2018 by researchers at Google.</p></li>
<li><p>BERT is an “encoder-only” transformer architecture.</p></li>
<li><p>Generally speaking, BERT consists of three modules:</p>
<ul>
<li><strong>Embedding.</strong> This module converts an array of one-hot encoded tokens into an array of vectors representing the tokens.</li>
<li><strong>Stack of encoders.</strong> These encoders are the Transformer encoders (BERT-base = 12, BERT-large = 24). They perform transformations over the array of representation vectors.</li>
<li><strong>Un-embedding.</strong> This module converts the final representation vectors into one-hot encoded tokens again.</li>
</ul></li>
</ul>
<p><span style="font-size:0.55em;">Devlin et al.&nbsp;2018</span></p>
</div><div class="column" style="width:15%;">
<p><img data-src="https://static.wikia.nocookie.net/muppet/images/e/e1/Bert_smile.png"></p>
</div>
</div>
</section>
<section id="why-un-embedding" class="slide level2">
<h2>Why un-embedding?</h2>
<ul>
<li><p>The un-embedding module is necessary for pretraining, but it is often unnecessary for downstream tasks.</p></li>
<li><p>Here, one would take the representation vectors output at the end of the stack of encoders, and use those as a vector representation of the text input, and train a smaller model on top of that (technically anything we covered last lecture!)</p></li>
</ul>
</section>
<section id="training-and-fine-tuning-of-bert" class="slide level2">
<h2>Training and Fine-Tuning of BERT</h2>
<ul>
<li><p>Pretrained on two task:</p>
<ul>
<li>Mask Language Modelling (LM): simply mask some percentage of the input tokens at random, and then predict those masked tokens</li>
<li>Next sentence prediction (NSP): predict sentence B from sentence A to model relationships between sentences</li>
</ul></li>
<li><p>This pre-training led to great performances in downstream tasks</p></li>
</ul>

<img data-src="img/bert_training.png" class="r-stretch quarto-figure-center"><p class="caption">Source: Devlin et al., 2018</p></section>
<section id="gpt-series-by-openai" class="slide level2">
<h2>GPT-Series by OpenAI</h2>
<ul>
<li><p>Generative Pre-trained Transformer (GPT), is a set of state-of-the-art large language model developed by OpenAI.</p></li>
<li><p>Particularly GPT-3, released publicly in November 2022 together with a chat interface, caused a lot of public attention.</p></li>
<li><p>Millions of users in a very short amount of time (faster than Facebook, Instagram, TikTok, etc…), now 1.5 Billion users</p></li>
</ul>
<center>
<p><img data-src="https://i0.wp.com/chatgptdutch.org/wp-content/uploads/2023/08/cropped-chatgpt-icon-logo.png" style="width:50.0%"></p>
</center>
</section>
<section id="high-level-architecture-and-training-of-gpt" class="slide level2">
<h2>High-level architecture and training of GPT</h2>
<ul>
<li>GPT are decoder-only models</li>
</ul>

<img data-src="img/gpt-series.png" class="r-stretch quarto-figure-center"><p class="caption">Source: Wikipedia</p></section>
<section id="zero-shot-learning" class="slide level2">
<h2>Zero-shot Learning</h2>
<ul>
<li><p>Zero-shot learning refers to the ability of a model to perform a task or make predictions on a set of classes or concepts that it has never seen or been explicitly trained on.</p></li>
<li><p>In other words, the model can generalize its pre-trained knowledge to new, unseen tasks without specific examples or training data for those tasks.</p></li>
<li><p>Classic machine learning models (last lecture) are typically trained on a specific set of classes, and their performance is evaluated on the same set of classes during testing.</p></li>
<li><p>Zero-shot learning extends this capability by allowing the model to handle tasks or categories that were not part of its training set be</p></li>
<li><p>This works, because of the model’s ability to capture and generalize information from the vast and varied data it has been exposed to during training.</p></li>
</ul>
</section>
<section id="zero-shot-text-classification-with-llms" class="slide level2">
<h2>Zero-Shot Text Classification with LLMS</h2>

<img data-src="img/text_analysis_fundamentals/Slide06.png" class="r-stretch"></section>
<section id="many-llms-are-available-at-huggingface.co" class="slide level2">
<h2>Many LLMS are available at huggingface.co</h2>

<img data-src="img/hugginface.png" class="r-stretch"></section>
<section id="workflow" class="slide level2">
<h2>Workflow</h2>
<ul>
<li><p>There are generally two ways in which we can work with these models:</p>
<ul>
<li>Assess the model via the hugging face API (only smaller rates per minute, but still useful)</li>
<li>Download and use the model on our own computer/GPU (requires Python, can be computationally intensive)</li>
</ul></li>
<li><p>In this course, we are going to “play around” with BERT models via the hugging face API</p>
<ul>
<li>We created a set of simple functions that allow to use different types of models for different purposes</li>
<li>To use them, it makes sense to create an account on hugging face and create an access token (homework!)</li>
</ul></li>
<li><p>For the project-phase, I will provide a more elaborate tutorial on how to use such models on your computer (but you don’t have to, if you don’t want to)</p>
<ul>
<li>This will require to install python and use it via R</li>
<li>Generally a bit more complicated</li>
</ul></li>
</ul>
</section>
<section id="using-a-bert-model-to-zero-shot-topics" class="slide level2">
<h2>Using a BERT model to zero-shot topics</h2>
<div class="cell">

</div>
<div class="cell" data-r.options="{&quot;width&quot;:120}">
<div class="sourceCode cell-code" id="cb19" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="fu">library</span>(ccsamsterdamR)</span>
<span id="cb19-2"><a href="#cb19-2"></a></span>
<span id="cb19-3"><a href="#cb19-3"></a>example_corpus <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb19-4"><a href="#cb19-4"></a>  <span class="at">id =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>),</span>
<span id="cb19-5"><a href="#cb19-5"></a>  <span class="at">text =</span> <span class="fu">c</span>(<span class="st">"To be, or not to be: that is the question."</span>, </span>
<span id="cb19-6"><a href="#cb19-6"></a>          <span class="st">"An atom is a particle that consists of a nucleus of protons and neutrons."</span>,</span>
<span id="cb19-7"><a href="#cb19-7"></a>          <span class="st">"Senate passes stopgap bill to avert government shutdown."</span>,</span>
<span id="cb19-8"><a href="#cb19-8"></a>          <span class="st">"S&amp;P 500 ends Friday slightly higher, major averages cruise to third week of gains: Live updates"</span>,</span>
<span id="cb19-9"><a href="#cb19-9"></a>          <span class="st">"Joe Burrow out for season: League to investigate Bengals over injury, looking whether team violated NFL policy"</span>,</span>
<span id="cb19-10"><a href="#cb19-10"></a>          <span class="st">"Joe Biden attended the final NFL game together with French president Emmanuel Macron."</span>))</span>
<span id="cb19-11"><a href="#cb19-11"></a></span>
<span id="cb19-12"><a href="#cb19-12"></a>output <span class="ot">&lt;-</span> <span class="fu">hf_zeroshot</span>(<span class="at">txt =</span> example_corpus<span class="sc">$</span>text, </span>
<span id="cb19-13"><a href="#cb19-13"></a>                      <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Poetry"</span>, <span class="st">"Politics"</span>, <span class="st">"Physics"</span>, <span class="st">"Finance"</span>, <span class="st">"Sport"</span> ),</span>
<span id="cb19-14"><a href="#cb19-14"></a>                      <span class="at">url =</span> <span class="st">"https://api-inference.huggingface.co/models/MoritzLaurer/deberta-v3-large-zeroshot-v1"</span>)</span>
<span id="cb19-15"><a href="#cb19-15"></a></span>
<span id="cb19-16"><a href="#cb19-16"></a>results <span class="ot">&lt;-</span> output <span class="sc">|&gt;</span> </span>
<span id="cb19-17"><a href="#cb19-17"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> <span class="fu">c</span>(<span class="st">"labels"</span>, <span class="st">"scores"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb19-18"><a href="#cb19-18"></a>  as_tibble <span class="sc">%&gt;%</span></span>
<span id="cb19-19"><a href="#cb19-19"></a>  <span class="fu">spread</span>(labels, scores)</span>
<span id="cb19-20"><a href="#cb19-20"></a>results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb20-1"><a href="#cb20-1"></a># A tibble: 6 × 6</span>
<span id="cb20-2"><a href="#cb20-2"></a>  sequence                                Finance Physics Poetry Politics  Sport</span>
<span id="cb20-3"><a href="#cb20-3"></a>  &lt;chr&gt;                                     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;</span>
<span id="cb20-4"><a href="#cb20-4"></a>1 An atom is a particle that consists of…  0.0003  0.999  0.0003   0.0003 0.0003</span>
<span id="cb20-5"><a href="#cb20-5"></a>2 Joe Biden attended the final NFL game …  0.0003  0.0002 0.0002   0.116  0.884 </span>
<span id="cb20-6"><a href="#cb20-6"></a>3 Joe Burrow out for season: League to i…  0       0      0        0      1.00  </span>
<span id="cb20-7"><a href="#cb20-7"></a>4 S&amp;P 500 ends Friday slightly higher, m…  1.00    0.0001 0.0001   0.0001 0.0001</span>
<span id="cb20-8"><a href="#cb20-8"></a>5 Senate passes stopgap bill to avert go…  0.0003  0.0001 0.0001   0.999  0.0001</span>
<span id="cb20-9"><a href="#cb20-9"></a>6 To be, or not to be: that is the quest…  0.0625  0.101  0.687    0.0829 0.0665</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="using-gpt-for-text-classification" class="slide level2">
<h2>Using GPT for text classification</h2>
<ul>
<li>The simplest way to use GPT is to simply paste text into the chat and ask for the relevant topics (in fact, let’s try this now!)</li>
</ul>

<img data-src="img/gpt_textprompt.png" class="r-stretch"><ul>
<li><p>Yet, for larger text corpora this is not feasible</p></li>
<li><p>To use GPT for text analysis purposes, we need to access the models via the Open AI API</p>
<ul>
<li>We created functions that allow to use the GPT models similarly to how we used the hugging face models</li>
<li>Requires to pay per token (luckily not too expensive, we will provide some accounts)</li>
</ul></li>
</ul>
</section>
<section id="using-gpt-3.5-turbo-for-a-simple-topic-classification" class="slide level2">
<h2>Using GPT-3.5-turbo for a simple topic classification</h2>
<div class="cell">

</div>
<ul>
<li><p>We simply pass the corpus to the function <code>gpt_zeroshot()</code> included in the package <code>ccsamsterdamR</code></p></li>
<li><p>We further pass a vector of labels that we want GPT to classify the text with.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="fu">library</span>(ccsamsterdamR)</span>
<span id="cb21-2"><a href="#cb21-2"></a></span>
<span id="cb21-3"><a href="#cb21-3"></a>output <span class="ot">&lt;-</span> <span class="fu">gpt_zeroshot</span>(<span class="at">txt =</span> example_corpus, </span>
<span id="cb21-4"><a href="#cb21-4"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Poetry"</span>, <span class="st">"Politics"</span>, <span class="st">"Physics"</span>, <span class="st">"Finance"</span>, <span class="st">"Sport"</span>),</span>
<span id="cb21-5"><a href="#cb21-5"></a>                       <span class="at">model =</span> <span class="st">"gpt-3.5-turbo-1106"</span>,</span>
<span id="cb21-6"><a href="#cb21-6"></a>                       <span class="at">justification =</span> <span class="cn">TRUE</span>)</span>
<span id="cb21-7"><a href="#cb21-7"></a></span>
<span id="cb21-8"><a href="#cb21-8"></a>result <span class="ot">&lt;-</span> example_corpus <span class="sc">|&gt;</span> </span>
<span id="cb21-9"><a href="#cb21-9"></a>  <span class="fu">left_join</span>(output) </span>
<span id="cb21-10"><a href="#cb21-10"></a>result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-r.options="{&quot;width&quot;:250}">
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb22-1"><a href="#cb22-1"></a># A tibble: 6 × 4</span>
<span id="cb22-2"><a href="#cb22-2"></a>     id text                                                                                                           labels   justification                                                                     </span>
<span id="cb22-3"><a href="#cb22-3"></a>  &lt;dbl&gt; &lt;chr&gt;                                                                                                          &lt;chr&gt;    &lt;chr&gt;                                                                             </span>
<span id="cb22-4"><a href="#cb22-4"></a>1     1 To be, or not to be: that is the question.                                                                     Poetry   Contains famous line from Shakespeare's Hamlet.                                   </span>
<span id="cb22-5"><a href="#cb22-5"></a>2     2 An atom is a particle that consists of a nucleus of protons and neutrons.                                      Physics  Describes basic concept of an atom.                                               </span>
<span id="cb22-6"><a href="#cb22-6"></a>3     3 Senate passes stopgap bill to avert government shutdown.                                                       Politics Refers to a specific legislative action in the Senate.                            </span>
<span id="cb22-7"><a href="#cb22-7"></a>4     4 S&amp;P 500 ends Friday slightly higher, major averages cruise to third week of gains: Live updates                Finance  Covers stock market performance and S&amp;P 500.                                      </span>
<span id="cb22-8"><a href="#cb22-8"></a>5     5 Joe Burrow out for season: League to investigate Bengals over injury, looking whether team violated NFL policy Sport    Reports on injury of football player Joe Burrow.                                  </span>
<span id="cb22-9"><a href="#cb22-9"></a>6     6 Joe Biden attended the final NFL game together with French president Emmanuel Macron.                          Politics Describes diplomatic engagement between Joe Biden and Emmanuel Macron at NFL game.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="comparison-with-classic-machine-learning" class="slide level2">
<h2>Comparison with classic machine learning</h2>
<ul>
<li><p>Let’s compare the zero-shot performance of GPT-3.5 against our best neural network classifier from last week in predicting genre from music lyrics.</p></li>
<li><p>To make things easier, we only use 87 songs from the lyrics data set.</p></li>
</ul>
<div class="cell" data-r.options="{&quot;width&quot;:120}">
<div class="sourceCode cell-code" id="cb23" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="fu">library</span>(textrecipes)</span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb23-4"><a href="#cb23-4"></a></span>
<span id="cb23-5"><a href="#cb23-5"></a><span class="co"># Set seed</span></span>
<span id="cb23-6"><a href="#cb23-6"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb23-7"><a href="#cb23-7"></a></span>
<span id="cb23-8"><a href="#cb23-8"></a><span class="co"># Read data</span></span>
<span id="cb23-9"><a href="#cb23-9"></a>lyrics_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/lyrics-data-prep.csv"</span>) <span class="sc">|&gt;</span>               </span>
<span id="cb23-10"><a href="#cb23-10"></a>  <span class="fu">mutate</span>(<span class="at">binary_genre =</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(Genre <span class="sc">==</span><span class="st">"Rock"</span>,<span class="st">"rock"</span>, <span class="st">"other"</span>),  </span>
<span id="cb23-11"><a href="#cb23-11"></a>                               <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"rock"</span>, <span class="st">"other"</span>) )) <span class="sc">|&gt;</span>        </span>
<span id="cb23-12"><a href="#cb23-12"></a>  <span class="fu">sample_frac</span>(<span class="at">size =</span> .<span class="dv">001</span>) <span class="sc">|&gt;</span>                                           </span>
<span id="cb23-13"><a href="#cb23-13"></a>  <span class="fu">select</span>(<span class="at">doc_id =</span> SLink, Artist, <span class="at">Song =</span> SName, </span>
<span id="cb23-14"><a href="#cb23-14"></a>         Genre, binary_genre, <span class="at">text =</span> Lyric)</span>
<span id="cb23-15"><a href="#cb23-15"></a><span class="fu">head</span>(lyrics_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<div class="sourceCode" id="cb24"><pre class="sourceCode numberSource output number-lines code-with-copy"><code class="sourceCode"><span id="cb24-1"><a href="#cb24-1"></a># A tibble: 6 × 6</span>
<span id="cb24-2"><a href="#cb24-2"></a>  doc_id                                     Artist            Song                             Genre binary_genre text </span>
<span id="cb24-3"><a href="#cb24-3"></a>  &lt;chr&gt;                                      &lt;chr&gt;             &lt;chr&gt;                            &lt;chr&gt; &lt;fct&gt;        &lt;chr&gt;</span>
<span id="cb24-4"><a href="#cb24-4"></a>1 /snoop-dogg/213-tha-gangsta-clicc.html     Snoop Dogg        213 Tha Gangsta Clicc            Hip … other        "[Sn…</span>
<span id="cb24-5"><a href="#cb24-5"></a>2 /far-east-movement/jello-feat-rye-rye.html Far East Movement Jello (feat. Rye Rye)            Pop   other        "Jel…</span>
<span id="cb24-6"><a href="#cb24-6"></a>3 /janet-jackson/got-till-its-gone.html      Janet Jackson     Got 'til It's Gone (feat. Q-Tip… Pop   other        "Wha…</span>
<span id="cb24-7"><a href="#cb24-7"></a>4 /tori-amos/yo-george.html                  Tori Amos         Yo George                        Rock  rock         "I s…</span>
<span id="cb24-8"><a href="#cb24-8"></a>5 /van-morrison/a-sense-of-wonder.html       Van Morrison      A Sense of Wonder                Rock  rock         "I w…</span>
<span id="cb24-9"><a href="#cb24-9"></a>6 /heart/together-now.html                   Heart             Together Now                     Rock  rock         "Dee…</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="predict-genre-with-the-neural-network-classifier" class="slide level2">
<h2>Predict genre with the neural network classifier</h2>
<ul>
<li><p>Because I saved the classifier from last week, I can now simply use it to predict the genre in the new subset</p></li>
<li><p>Remember, it was multilayer perceptrion with 1 hidden layer (6 nodes) and trained on 10,445 songs.</p></li>
</ul>
<div class="cell" data-r.options="{&quot;width&quot;:120}">
<div class="sourceCode cell-code" id="cb25" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Setting relevant metrics</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>class_metrics <span class="ot">=</span> <span class="fu">metric_set</span>(accuracy, precision, recall, f_meas)</span>
<span id="cb25-3"><a href="#cb25-3"></a></span>
<span id="cb25-4"><a href="#cb25-4"></a><span class="co"># Loading the model from last week</span></span>
<span id="cb25-5"><a href="#cb25-5"></a><span class="fu">load</span>(<span class="st">"results/m_ann.Rdata"</span>)</span>
<span id="cb25-6"><a href="#cb25-6"></a></span>
<span id="cb25-7"><a href="#cb25-7"></a><span class="co"># Predicting the new subset of the sample (the 87 songs!)</span></span>
<span id="cb25-8"><a href="#cb25-8"></a>predict_ann <span class="ot">&lt;-</span> <span class="fu">predict</span>(m_ann, <span class="at">new_data=</span>lyrics_data) <span class="sc">|&gt;</span></span>
<span id="cb25-9"><a href="#cb25-9"></a>  <span class="fu">bind_cols</span>(<span class="fu">select</span>(lyrics_data, binary_genre)) <span class="sc">|&gt;</span></span>
<span id="cb25-10"><a href="#cb25-10"></a>  <span class="fu">rename</span>(<span class="at">predicted=</span>.pred_class, <span class="at">actual=</span>binary_genre)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="predicting-genre-with-gpt-3.5" class="slide level2">
<h2>Predicting genre with GPT-3.5</h2>
<ul>
<li><p>To predict the data with GPT (I am choosing the GPT-3.5 Turbo version here), we don’t have to engage in elaborate preprocessing. We simply create an id-variable (helps to later combine predictions and actual gold standard).</p></li>
<li><p>However, the GPT API allows on a certain amount of tokens per minute (~10,000) AND also only a certain amount of tokens per prompt (for this model at least 32,000)</p></li>
<li><p>This requires us to get creative and do a few things:</p>
<ul>
<li>split the sample in smaller chunks so that we can prompt one after the other</li>
<li>map across those chunks and capture prediction in each step</li>
<li>add a delay (<code>Sys.sleep(10)</code> = 10 seconds break) in between prompts</li>
</ul></li>
</ul>
</section>
<section id="predicting-genre-with-gpt-3.5-1" class="slide level2">
<h2>Predicting genre with GPT-3.5</h2>
<div class="cell">

</div>
<ul>
<li>First, we have to create and ID-variable and split the data in small chunks:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb26" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># Create id variable</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>lyrics_data_gpt <span class="ot">&lt;-</span> lyrics_data <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">n</span>()) <span class="sc">|&gt;</span> <span class="fu">select</span>(id, text)</span>
<span id="cb26-3"><a href="#cb26-3"></a></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="co"># Split data set in smaller chunks</span></span>
<span id="cb26-5"><a href="#cb26-5"></a>splits <span class="ot">&lt;-</span> lyrics_data_gpt <span class="sc">|&gt;</span> <span class="fu">gpt_split_data</span>(<span class="at">n_per_group =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># Actual prompting via the API</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>map_results <span class="ot">&lt;-</span> <span class="fu">map_df</span>(splits, <span class="cf">function</span>(x) {</span>
<span id="cb27-3"><a href="#cb27-3"></a>  output <span class="ot">&lt;-</span> <span class="fu">gpt_zeroshot</span>(</span>
<span id="cb27-4"><a href="#cb27-4"></a>    <span class="at">txt =</span> x,</span>
<span id="cb27-5"><a href="#cb27-5"></a>    <span class="at">expertise =</span> <span class="st">"You are in expert in classifying the genre of a song based on its lyrics."</span>,</span>
<span id="cb27-6"><a href="#cb27-6"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"rock"</span>, <span class="st">"other"</span>),</span>
<span id="cb27-7"><a href="#cb27-7"></a>    <span class="at">model =</span> <span class="st">"gpt-3.5-turbo-1106"</span>)</span>
<span id="cb27-8"><a href="#cb27-8"></a>  <span class="fu">Sys.sleep</span>(<span class="dv">10</span>)   <span class="co"># Adding 10 seconds delay between prompts to avoid token-per-minute rate limit</span></span>
<span id="cb27-9"><a href="#cb27-9"></a>  output</span>
<span id="cb27-10"><a href="#cb27-10"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Finally, we can join the resulting predictions with the original data:</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb28" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Join predictions and original gold standard</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>predict_gpt <span class="ot">&lt;-</span> lyrics_data_gpt <span class="sc">|&gt;</span>  </span>
<span id="cb28-3"><a href="#cb28-3"></a>  <span class="fu">left_join</span>(map_results) <span class="sc">|&gt;</span> <span class="fu">left_join</span>(lyrics_data) <span class="sc">|&gt;</span> <span class="fu">select</span>(id, labels, binary_genre) <span class="sc">|&gt;</span> </span>
<span id="cb28-4"><a href="#cb28-4"></a>  <span class="fu">mutate</span>(<span class="at">labels =</span> <span class="fu">factor</span>(labels, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"rock"</span>, <span class="st">"other"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="comparison-between-neural-network-and-gpt-3.5" class="slide level2">
<h2>Comparison between neural network and GPT-3.5</h2>
<ul>
<li><p>We can see that the neural network does better overall, but bear in mind that it was trained on a lot of data (10,445 songs!)</p></li>
<li><p>GPT-3.5 yields a quite astonishing performance, given that it was not trained to do this task at all!</p></li>
</ul>
<div class="colums">
<div class="column" style="width:50%;">
<div class="cell" data-output-location="column-fragment">
<div class="sourceCode cell-code" id="cb29" data-code-line-numbers="true"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a><span class="fu">bind_rows</span>(</span>
<span id="cb29-2"><a href="#cb29-2"></a>  predict_ann <span class="sc">|&gt;</span> </span>
<span id="cb29-3"><a href="#cb29-3"></a>  <span class="fu">class_metrics</span>(<span class="at">truth =</span> actual, </span>
<span id="cb29-4"><a href="#cb29-4"></a>                <span class="at">estimate =</span> predicted) <span class="sc">|&gt;</span> </span>
<span id="cb29-5"><a href="#cb29-5"></a>  <span class="fu">mutate</span>(<span class="at">approach =</span> <span class="st">"classic ML: neural network"</span>),</span>
<span id="cb29-6"><a href="#cb29-6"></a>  predict_gpt <span class="sc">|&gt;</span> </span>
<span id="cb29-7"><a href="#cb29-7"></a>  <span class="fu">class_metrics</span>(<span class="at">truth =</span> binary_genre, </span>
<span id="cb29-8"><a href="#cb29-8"></a>                <span class="at">estimate =</span> labels) <span class="sc">|&gt;</span> </span>
<span id="cb29-9"><a href="#cb29-9"></a>  <span class="fu">mutate</span>(<span class="at">approach =</span> <span class="st">"zero-shot learning: gpt-3.5"</span>)</span>
<span id="cb29-10"><a href="#cb29-10"></a> ) <span class="sc">|&gt;</span> </span>
<span id="cb29-11"><a href="#cb29-11"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> .metric, <span class="at">y =</span> .estimate, </span>
<span id="cb29-12"><a href="#cb29-12"></a>             <span class="at">fill =</span> approach)) <span class="sc">+</span></span>
<span id="cb29-13"><a href="#cb29-13"></a>  <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="fu">position_dodge</span>()) <span class="sc">+</span></span>
<span id="cb29-14"><a href="#cb29-14"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">y =</span> .estimate <span class="sc">-</span>.<span class="dv">05</span>, </span>
<span id="cb29-15"><a href="#cb29-15"></a>                <span class="at">label =</span> <span class="fu">round</span>(.estimate, <span class="dv">2</span>)), </span>
<span id="cb29-16"><a href="#cb29-16"></a>            <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="at">width =</span> .<span class="dv">75</span>)) <span class="sc">+</span></span>
<span id="cb29-17"><a href="#cb29-17"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb29-18"><a href="#cb29-18"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb29-19"><a href="#cb29-19"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>) <span class="sc">+</span></span>
<span id="cb29-20"><a href="#cb29-20"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">""</span>, <span class="at">y =</span> <span class="st">"Score"</span>, <span class="at">fill =</span> <span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="column" style="width:48%;">
<p><img data-src="img/gpt_results.png"></p>
</div>
</div>
</section>
<section id="examples-in-the-literature" class="slide level2">
<h2>Examples in the literature</h2>
<div class="columns">
<div class="column" style="width:80%;">
<ul>
<li><p>Baluff et al.&nbsp;(2023) investigated a recent case of media capture, a mutually corrupting relationship between political actors and media organizations.</p></li>
<li><p>This case involves former Austrian chancellor who allegedly colluded with a tabloid newspaper to receive better news coverage in exchange for increased ad placements by government institutions.</p></li>
<li><p>They implemented automated content analysis (using BERT) of political news articles from six prominent Austrian news outlets spanning 2012 to 2021 (n = 188,203) and adopted a difference-in-differences approach to scrutinize political actors’ visibility and favorability in news coverage for patterns indicative of the alleged serious breach of professional political and journalistic norms.</p></li>
</ul>
</div><div class="column" style="width:20%;">
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/8/82/Sebastian_Kurz_%282018-02-28%29_%28cropped%29.jpg"></p>
</div>
</div>
</section>
<section id="methods" class="slide level2">
<h2>Methods</h2>
<ul>
<li><p>Used a German-language GottBERT model (Scheible et al., 2020) that they further fine-tuned for the task using publicly available data from the AUTNES Manual Content Analysis of the Media Coverage 2017 and 2019 (Galyga et al., 2022; Litvyak et al., 2022c)</p></li>
<li><p>Comparatively difficult task, but were able to reach a satisfactory F1-Score of 0.77 (precision = 0.77, recall = 0.77).</p></li>
</ul>

<img data-src="img/kurz1.png" class="r-stretch"></section>
<section id="findings" class="slide level2">
<h2>Findings</h2>
<ul>
<li><p>Our findings indicate a substantial increase in the news coverage of the former Austrian chancellor within the news outlet that is alleged to have received bribes.</p></li>
<li><p>In contrast, several other political actors did not experience similar shifts in visibility nor are similar patterns identified in other media outlets.</p></li>
</ul>

<img data-src="img/kurz2.png" class="r-stretch"></section></section>
<section>
<section id="summary-and-conclusion" class="title-slide slide level1 center" data-background-color="steelblue">
<h1>Summary and conclusion</h1>

</section>
<section id="a-look-back-at-the-chronology-of-nlp" class="slide level2">
<h2>A Look Back at the Chronology of NLP</h2>

<img data-src="img/timeline/Slide1b.png" class="r-stretch"></section>
<section id="a-look-back-at-the-chronology-of-nlp-1" class="slide level2">
<h2>A Look Back at the Chronology of NLP</h2>

<img data-src="img/timeline/Slide2b.png" class="r-stretch"></section>
<section id="a-look-back-at-the-chronology-of-nlp-2" class="slide level2">
<h2>A Look Back at the Chronology of NLP</h2>

<img data-src="img/timeline/Slide3b.png" class="r-stretch"></section>
<section id="explosion-in-model-size" class="slide level2">
<h2>Explosion in model size?</h2>

<img data-src="04_largelanguagemodels_2023_files/figure-revealjs/unnamed-chunk-26-1.png" width="768" class="r-stretch"></section>
<section id="environmental-impact" class="slide level2">
<h2>Environmental Impact</h2>

<img data-src="https://hai.stanford.edu/sites/default/files/inline-images/AIIndex_2023_StateofAI_Blog_4.jpg" class="r-stretch"></section>
<section id="ethical-considerations" class="slide level2">
<h2>Ethical considerations</h2>
<ul>
<li><p>Training large language models requires significant computational resources, contributing to a substantial carbon footprint. Ethical considerations involve assessing the environmental impact of developing and deploying such models.</p></li>
<li><p>LLMs can inherit and perpetuate biases present in their training data.</p></li>
<li><p>This can result in the generation of biased or unfair content, reflecting and potentially amplifying societal biases and stereotypes.</p></li>
<li><p>Developers and users must be aware of the potential for bias and take steps to mitigate it during model training and deployment.</p></li>
<li><p>The fact that some LLMs are developed, trained, and employed behind closed doors causes yet another ethical dilemma in using them!</p></li>
</ul>
</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li><p>Advancement in NLP and AI are fast-paced; difficult to keep up</p></li>
<li><p>LLMs promise immense potential for communication research</p></li>
<li><p>Yet, large language models can contain biases or even hallucinate!</p>
<ul>
<li>Validation, validation, validation!</li>
</ul></li>
</ul>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://s3.amazonaws.com/static.rogerebert.com/uploads/review/primary_image/reviews/great-movie-ai-artificial-intelligence-2001/EB20110707REVIEWS08110709988AR.jpg"></p>
<p></p><figcaption>A.I (Steven Spielberg)</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://mir-s3-cdn-cf.behance.net/project_modules/max_1200/ea5cab25137457.563425fa7c93f.png"></p>
<p></p><figcaption>Her (Spike Jones)</figcaption><p></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://www.azcentral.com/gcdn/-mm-/8595b75e3791fcb4aef999b94940f74898e5ea59/c=3-0-1591-897/local/-/media/2015/04/22/Phoenix/Phoenix/635653113360425789-alicia-vikander.jpg"></p>
<p></p><figcaption>Ex Machina (Alex Garland)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="section-2" class="slide level2" data-background-video="video/info.mp4">
<h2></h2>
</section></section>
<section>
<section id="thank-you-for-your-attention" class="title-slide slide level1 center" data-background-color="steelblue">
<h1>Thank you for your attention!</h1>

</section>
<section id="required-reading" class="slide level2">
<h2>Required Reading</h2>
<p><br><br></p>
<p>Kroon, A., Welbers, K., Trilling, D., &amp; van Atteveldt, W. (2023). Advancing Automated Content Analysis for a New Era of Media Effects Research: The Key Role of Transfer Learning. Communication Methods and Measures, 1-21</p>
<p><br></p>
<p><em>(available on Canvas)</em></p>
</section>
<section id="reference" class="slide level2 smaller">
<h2>Reference</h2>
<ul>
<li><p>Alammar, J. (2018). The illustrated Transformer. Retrieved from: https://jalammar.github.io/illustrated-transformer/</p></li>
<li><p>Andrich, A., Bachl, M., &amp; Domahidi, E. (2023). Goodbye, Gender Stereotypes? Trait Attributions to Politicians in 11 Years of News Coverage. Journalism &amp; Mass Communication Quarterly, 100(3), 473-497. https://doi-org.vu-nl.idm.oclc.org/10.1177/10776990221142248</p></li>
<li><p>Balluff, P., Eberl, J., Oberhänsli, S. J., Bernhard, J., Boomgaarden, H. G., Fahr, A., &amp; Huber, M. (2023, September 15). The Austrian Political Advertisement Scandal: Searching for Patterns of “Journalism for Sale”. https://doi.org/10.31235/osf.io/m5qx4</p></li>
<li><p>Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.</p></li>
<li><p>Kroon, A., Welbers, K., Trilling, D., &amp; van Atteveldt, W. (2023). Advancing Automated Content Analysis for a New Era of Media Effects Research: The Key Role of Transfer Learning. Communication Methods and Measures, 1-21</p></li>
<li><p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … &amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.</p></li>
</ul>
</section>
<section id="example-exam-question-multiple-choice" class="slide level2">
<h2>Example Exam Question (Multiple Choice)</h2>
<p>How are word embeddings learned?</p>
<p><br></p>
<p>A. By assigning random numerical values to each word</p>
<p>B. By analyzing the pronunciation of words</p>
<p>C. By scanning the context of each word in a large corpus of documents</p>
<p>D. By counting the frequency of words in a given text</p>
</section>
<section id="example-exam-question-multiple-choice-1" class="slide level2">
<h2>Example Exam Question (Multiple Choice)</h2>
<p>How are word embeddings learned?</p>
<p><br></p>
<p>A. By assigning random numerical values to each word</p>
<p>B. By analyzing the pronunciation of words</p>
<p><strong>C. By scanning the context of each word in a large corpus of documents</strong></p>
<p>D. By counting the frequency of words in a given text</p>
</section>
<section id="example-exam-question-open-format" class="slide level2">
<h2>Example Exam Question (Open Format)</h2>
<p>What does zero-shot learning refer to in the context of large language models?</p>
<div class="fragment">
<p><br></p>
<p>In the context of large language models, zero-shot learning refers to the ability of a model to perform a task or make predictions on a set of classes or concepts that it has never seen or been explicitly trained on. Essentially, the model can generalize its knowledge to new, unseen tasks without specific examples or training data for those tasks.</p>
<p>In traditional machine learning, models are typically trained on a specific set of classes, and their performance is evaluated on the same set of classes during testing. Zero-shot learning extends this capability by allowing the model to handle tasks or categories that were not part of its training set.</p>
<p>In the case of large language models like GPT-3, which is trained on a diverse range of internet text, zero-shot learning means the model can understand and generate relevant responses for queries or prompts related to concepts it hasn’t been explicitly trained on. This is achieved through the model’s ability to capture and generalize information from the vast and varied data it has been exposed to during training.</p>
<p><img src="img/logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>Computational Analysis of Digital Communication</p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="04_largelanguagemodels_2023_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        function fireSlideChanged(previousSlide, currentSlide) {

          // dispatch for htmlwidgets
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for reveal
        if (window.Reveal) {
          window.Reveal.addEventListener("slidechanged", function(event) {
            fireSlideChanged(event.previousSlide, event.currentSlide);
          });
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        setTimeout(function() {
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    

</body></html>