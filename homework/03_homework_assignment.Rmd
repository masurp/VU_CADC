---
title: 'Homework 3: Supervised Text Classification'
author: "Philipp Masur"
date: ""
output:
  html_document:
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r opts, echo = FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, results = TRUE, message = FALSE, warning = FALSE)
```

# Formalities

- Name:         [ENTER YOUR NAME HERE]
- Student ID:   [ENTER YOUR STUDENT ID HERE]   

In the end, klick on "knit" and upload the respective html-output file to Canvas. Please add your name and lastname to the output file name:
e.g., 02_homework_assignment_NAME-LASTNAME.html


# Introduction 

In this homework, you are going to work with data provided by Ahmed, Traore, & Saad (2018), who studying the detection of fake news in online news articles. We ask you to evaluate how well a Naive Bayes algorithm succeeds in predicting whether a news article is fake or not. 


## Loading data

First, we are going to load the data. It comes in two batches (download it from canvas: Fake.csv & True.csv): the first contains more than 20,000 fake news articles; the second contains 21,000 true articles. We load both individually, add a column that designates them as either fake or true (fake: true = no; true: true = yes). We then combine both and have a look at the data set.

```{r}
library(tidyverse)
fake <- read_csv("Fake.csv") %>% mutate(true = "no")
true <- read_csv("True.csv") %>% mutate(true = "yes")

d <- rbind(fake, true)
head(d)
```

As you can see, the data set contains articles of different subjects. Can you create a bar plot that shows how many articles per subject are included in the data set? (Bonus: Try to reorder the bar plot so that the subject with the most articles is shown first and the subject with the least articles at last).

**Question:** Which subjects dominate the corpus?


```{r}
# Solution here
```

**Answer:** [Add your answer here]

## Combining title and text

Similar to the Amazon Review, we have two potential sources of information for the classification: The title and the text itself. It would be unfortunate to only use one of them. For example, not using the title would be a shame as it is very possible that the title already tells a lot about whether or not a news article is fake. We hence combine both columns into one. 

```{r}
d <- d %>%
  mutate(text2 = str_c(title, text, sep = " "))
```


# Text preprocessing

Next, we engage in the preprocessing. For supervised machine learning, this means create a train and test data set and thinking about meaningful text preprocessing steps. 

## Creating train and test set

First, create a training and a test set. Think about meaningful partitions. Please justify why you choose a certain percentage. Don't forget to use set.seed to ensure reproducibility. 

```{r}
# Solution here
```

**Answer:** [Add your answer here]

## Text preprocessing 

Now think about meaningful text preprocessing (Removing stopwords? Trimming the data set?). Also justify your steps below. 

```{r}
# Solution here
```

**Answer:** [Add your answer here]


# Machine Learning

## Training the algorithm

Now, we can train the model. Don't forget to load the package "quanteda.textmodels". 

```{r}
# Solution here
```

## Testing the model on the training set

Now, we should quickly check the accuracy of the algorithm in predicting the "train" set. This of course should be really high as we trained it on this set. 

```{r}
# Solution here
```


## Validating on the test data

More importantly, we need to validate the algorithm performance. To do this, we need to preprocess the "test" data set in the exact same way as the train data set. Don't forget to use `dfm_match()` to make sure that the features are ordered in the same way. Then move on to compute the accuracy and other performance indicators (e.g., precision, recall, F1-Score). You can use the `caret` package for this as well. How well does the algorithm predict fake news in the data set?

```{r}
# Solution here
```

**Answer:** [Add your answer here]

